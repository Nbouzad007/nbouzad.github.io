<html>
        <head>
         <link rel="stylesheet" href = "ex2.css"/>   
        </head>
        <body>
            
        <div class="cv-contenu">
            <div class="entete">
            
            </div>
            <div class="corps">
                <div class="agauche">
                <img src="Maelpegnyph.jpg" alt="Photo de Mael Pégny"/>
                <h1> Présentation du Professeur </h1>
                
                    <strong>Mael Pegny</strong></br>
                    Chercheur post-doctoral en Pilosophie et science physiques</br>
                    Maitre de conférence sur l'intelligence artificielle</br>
                    
                     <a href="https://www.linkedin.com/in/ma%C3%ABl-p%C3%A9gny-b949b445/?originalSubdomain=fr"> LinkedIn de Monsieur Pégny</a>
                    
                <h1> Biographie </h1>
                    <p> Né en 1983, Maël Pégny a étudié la philosophie, la logique et la physique. Il a soutenu en 2013 une thèse de philosophie des sciences sur la définition du calcul. Il a travaillé depuis lors sur l'histoire et la philosophie de l'informatique, en s'intéressant autant aux évolutions les plus récentes qu'à la compréhension du calcul comme technique cognitive sur le temps long.<br/></p>
<p>Il explore depuis 3 ans un territoire à l'intersection de l'éthique et de la philosophie des sciences, en examinant comment les nouveaux modèles d'IA modifient à la fois la science et la vie politique.</p><br/><a href="https://philpeople.org/profiles/mael-pegny"> Site de l'Université de Lorraine</a>
            </div>
                
                <div class="adroite">
              <h2> Résumé de la conférence </h2>
            <p id="toto"> M. Pegny commence d’abord par aborder la notion de vie privée du point de vue historique, cette notion étant construite en relation avec les institutions, dans sa conception la plus expansive (rapport à l’Etat, rapport à la famille, etc). La vie privée est un concept qui impacte à la fois les individus sur le plan psychologique, et aussi les régimes politiques. M. Pegny poursuit sur l’informatique en le définissant comme une technique cognitive (Goody) globale affectant l‘enregistrement, la communication et le raisonnement.
Dès la fin des années 1950, l’informatique est vue comme un problème pour le respect de la vie privée et des libertés publiques : apparaissent alors des législations sur la protection des données personnelles. Le droit des données personnelles est beaucoup plus large que la vie privée. Les données personnelles représentent un enjeu stratégique pour l‘ensemble des droits de la personne physique. En effet, la collecte et la formation de connaissances (réelles ou prétendues) sur les individus, notamment par les institutions, pose directement la question du respect de la vie privée. La question qui se pose à la suite de cela est celle de la portée exacte 
de la vie privée ? Celle-ci englobe plusieurs notions allant de l‘intimité à des notions beaucoup plus larges : discrimination, autonomie, réputation, identité...
Récemment, le Machine Learning (sous branche de l’IA) a permis de changer d'échelle : on collecte énormément de données, rapidement, et de différents types (Volume, Vitesse, Variété).
On collecte ces données parce qu’on peut les analyser, notamment avec le machine learning. Mais toutes les questions liées à la vie privée ne sont pas liées au Machine Learning. l’Idée fondamentale du machine learning est qu’au lieu de donner des instructions explicites pour exécuter une tâche,il faudrait laisser le système apprendre à partir de l‘analyse statistique d‘un grand nombre d‘exemples, d’où la citation proposé par M. Pegny “Les IAs ne se programment pas, elles se dressent.” C'est une tentative pour créer un nouveau paradigme de programmation contournant les difficultés de la jeune IA, notamment les systèmes experts.
Après avoir montré des exemples de modèles récents de Machine Learning (Automatisation d‘analyses de données et de modèles simples, extension méthodologique , Montée en échelle (nombre de points de données, de variables)), M. Pégny nous rappelle qu'ils sont des modèles statistiques et peuvent donc permettre de représenter les populations pour les institutions.
Différents acteurs procèdent à une surveillance de masse des individus. En effet, Bruce Schneier disait : “les institutions n‘ont jamais amassé autant de données sur les individus, et disposé d‘autant de moyens de surveillance continue des moindres aspects de leur existence de manière largement subreptice”. Parmi ces moyens de surveillance de masse on peut trouver : la Géolocalisation de masse par le téléphone portable, l’Accès aux conversations ordinaires et aux réseaux de relation par réseaux sociaux, la Numérisation des informations financières et commerciales, la visualisation des Moteurs de recherche, etc. Les acteurs procédant à cette surveillance peuvent être publics, comme l’Etat (Révélation sur la surveillance de masse des services américains par E. Snowden (2011)), ou encore privés, mais pour des enjeux différents. La mise en place de cette surveillance peut avoir des fins marketing : c’est ce que S. Zuboff appelle le “capitalisme de surveillance”, en particulier pour effectuer de la publicité ciblée fondée sur quatre piliers : la Création d‘un profil d‘utilisateur à partir de ses traces numériques, l’Emploi de modèles Machine Learning prédictifs du comportement des utilisateurs, la Capacité de customisation à bas coût de l‘environnement, le Grand nombre d‘utilisateurs permettant les études statistiques. Cette combinaison de la surveillance et de la vente crée une véritable “économie de la manipulation” nous dit M. 
Pégny. Cette manipulation est basée sur la psychologie comportementale, les statistiques et les données massives, le consommateur est peu conscient de l‘ampleur des données collectées, de la présence et de la nature du ciblage, il y a donc une véritable Exploitation des vulnérabilités psychologiques de celui-ci. Au-delà de l’aspect économique, c’est véritablement de la propagande qu’il est possible de faire à partir de la surveillance de masse, réalisée à partir du profilage établi grâce aux données.
Également parmi les impact de l’IA sur la vie privée, M. Pégny aborde la “mort de l’anonymat en ligne” puisqu’il est possible de procéder à l’identification des utilisateurs
Cette identification serait nécessaire à l‘action des institutions bureaucratiques sur les individus, celle-ci étant réalisée par le croisement de données. a partir ce certaines bases de données, il serait donc possible d’induire, de conclure, d’inférer certaines informations (exemple de Facebook infère informations sensibles et état psychologique à partir des listes d‘amis et du comportement en ligne.) le machine learning a donc pour but d’exploiter les corrélations entre une information cible et de nombreuses données intuitivement sans aucune relation. La démonstration se poursuit avec “la mort de l’anonymat dans l’espace public” en se concentrant sur la reconnaissance faciale. Il y a deux formes d'outils (Facial Recognition Technology, FRT) : la Reconnaissance à partir de photographies, notamment pour des individus arrêtés par la police; et la Reconnaissance en direct à partir d‘images de caméra de vidéosurveillance dans l‘espace public (live FRT).
C‘est la deuxième technologie qui focalise le débat, sur le plan Juridique, car on assiste à l' application de pratiques d‘identification réservées aux suspects et aux criminels à l‘ensemble de la population ; et sur le plan Symbolique puisque cela constitue une forme de mort de l‘anonymat dans l‘espace public.
Différents dysfonctionnements ont pu être constatés : certains tests à grande échelle de la reconnaissance faciale dans l‘espace public ont tourné à la catastrophe, il y a d’ailleurs quelques cas d‘identification ratés même en reconnaissance faciale ordinaire.
De plus, il y a de véritables écarts de performance significatifs en défaveur de certaines populations (femmes, peaux sombres, enfants...). Pour la collecte de données, il est donc nécessaire d'être  en conditions naturelles et à grande échelle pour live FRT. Le développement de la Live FRT constitue en soi un tournant juridique. En effet, il est nécessaire d’avoir de vastes bases de données collectées dans des conditions naturelles pour l‘entraînement des modèles. En pratique, ces bases de données de plus en plus anarchiques 
(faible contrôle qualité,affaiblissement du consentement). L‘ approche d‘usage réglementé entérine la collection de données biométriques à l'échelle d‘une population sans consentement. il y a tout une controverse autour des bases de données modiques comparées à une base de données biométriques centralisée à l‘échelle d‘une population. parmi les inconvénients de la reconnaissance faciale dans l’espace public, on trouve de Nombreuses pratiques inquiétantes dans les polices des pays démocratiques : le Manque de transparence des institutions sur l‘usage, le Manque d‘expertise interne sur l‘outil et de contrôle qualité, l’Emploi très peu encadré des outils par la police, la Présence massive d‘innocents et de personnes arrêtées mais non condamnées dans les bases, ou encore les Pratiques abusives (identification de manifestants Black Lives Matter). M. Pégny poursuit ensuite sur la notion de donnée personnelle, sa limite ainsi que la nécessité de dépasser cette notion. 
enfin Le machine learning rend ambiguë la distinction entre donnée et programme, techniquement mais aussi juridiquement : il est nécessaire de clarifier le rapport entre traitement et statut de donnée personnelle.</p>
                <a id="titi" href="https://www.ethics-ai.fr/mael-pegny-lexplicabilite-de-lia-opaque-comme-moment-dans-lhistoire-de-la-bureaucratie-sur-la-depersonnalisation-sans-formalisation-de-la-decision%EF%BF%BC-%EF%BF%BC/"> Autre conférence de M.Pégny sur le meme sujet</a>
                    
                    
                    </div>
                </div>
                        
            
        
         </div>
        </body>
    </html>